{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMsqA2ByC4U8Jn4/kqyj63n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamscj/abuse_detection/blob/main/Minor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lya5k6Gi8K-O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet50(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxBrD-jw8vI1",
        "outputId": "90cf8e82-0740-4617-b021-128e662a6792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "Jlus_S8TXr9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Resize frames to 128x128 pixels\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "UiM1HPY385CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(frame):\n",
        "    frame = transform(frame)\n",
        "    frame = torch.unsqueeze(frame, 0)\n",
        "    with torch.no_grad():\n",
        "        features = model(frame)\n",
        "    return features.squeeze()"
      ],
      "metadata": {
        "id": "UhrCdj3E9E2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random"
      ],
      "metadata": {
        "id": "d-BkvoKL9G4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kor3HcaV9KII",
        "outputId": "526d2e6b-d9a0-45b8-9f30-415c4978e6e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_dir = '/content/drive/MyDrive/MINOR_DATASET/UBI_FIGHTS/fight'\n",
        "output_dir = '/content/drive/MyDrive/MINOR_OUTPUT'"
      ],
      "metadata": {
        "id": "fBb_0WZx-dvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_files = os.listdir(video_dir)\n",
        "random.shuffle(video_files)\n",
        "video_files"
      ],
      "metadata": {
        "id": "6Gh-E3uz_e41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(video_files))\n",
        "num_frames_to_extract = 10  # Number of frames to extract from each video"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYlCOBjfAC6L",
        "outputId": "621a5bf8-a59d-4d26-f5c0-efad500d639d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "LPN2VMC1BphZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_frames_from_video(video_path,cnt):\n",
        "    frames = []\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    print(len(frames))\n",
        "    return frames"
      ],
      "metadata": {
        "id": "kS1y2u7oIKW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import time\n",
        "import datetime"
      ],
      "metadata": {
        "id": "83cuwLtUIPKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_length(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = frame_count / fps\n",
        "    cap.release()\n",
        "    return duration"
      ],
      "metadata": {
        "id": "l64DrAmoKG5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_number_list(n):\n",
        "    number_list = list(range(1, n))\n",
        "    random.shuffle(number_list)\n",
        "    return number_list[:10]"
      ],
      "metadata": {
        "id": "o9GlZrwJko7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_particular_frames(video_path, frame_numbers):\n",
        "    frames = []\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    for frame_number in frame_numbers:\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            frames.append(frame)\n",
        "    cap.release()\n",
        "    return frames"
      ],
      "metadata": {
        "id": "Wht22GOTlCxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_frame_count(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    cap.release()\n",
        "    return frame_count"
      ],
      "metadata": {
        "id": "nCGkPuaDc6mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for video_file in video_files[100:]:\n",
        "    video_path = os.path.join(video_dir, video_file)\n",
        "    frame_count=get_video_frame_count(video_path)\n",
        "    frame_list=generate_random_number_list(frame_count)\n",
        "    # frames = load_frames_from_video(video_path,frame_count)\n",
        "    frames = get_particular_frames(video_path,frame_list)\n",
        "    if len(frames) < num_frames_to_extract:\n",
        "        continue  # Skip videos with fewer frames than required\n",
        "\n",
        "    selected_frames = random.sample(frames, num_frames_to_extract)\n",
        "    features = []\n",
        "\n",
        "    for frame in selected_frames:\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert frame to RGB format\n",
        "        pil_frame = Image.fromarray(frame)  # Convert NumPy array to PIL image\n",
        "        transformed_frame = transform(pil_frame)\n",
        "        transformed_frame = torch.unsqueeze(transformed_frame, 0)\n",
        "        with torch.no_grad():\n",
        "            frame_features = model(transformed_frame)\n",
        "        features.append(frame_features.squeeze())\n",
        "\n",
        "    features = torch.stack(features)\n",
        "    output_file = os.path.join(output_dir, f'{video_file}.pt')\n",
        "    torch.save(features, output_file)\n",
        "    print(video_file + \" trained\")\n",
        "    # time.sleep(5)"
      ],
      "metadata": {
        "id": "9wEvU9LNIR5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "# Define the directory containing the .pt files\n",
        "directory = '/content/drive/MyDrive/MINOR_OUTPUT'\n",
        "\n",
        "# Load and concatenate the features from all .pt files\n",
        "combined_features = []\n",
        "for file_name in os.listdir(directory):\n",
        "    if file_name.endswith('.pt'):\n",
        "        file_path = os.path.join(directory, file_name)\n",
        "        features = torch.load(file_path)\n",
        "        combined_features.append(features)\n",
        "\n",
        "combined_features = torch.cat(combined_features, dim=0)\n",
        "\n",
        "# Save the combined features to a single .pt file\n",
        "output_file = '/content/drive/MyDrive/MINOR_OUTPUT/model.pt'\n",
        "torch.save(combined_features, output_file)\n"
      ],
      "metadata": {
        "id": "HIVFAfgxivBt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}